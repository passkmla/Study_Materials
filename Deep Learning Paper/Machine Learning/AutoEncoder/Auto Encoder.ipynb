{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP(Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP는 아래의 그림과 같이 입력단과 여러 개의 hidden layer 및 출력단으로 구성된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP는 여러 개의 hidden 레이어를 이용하여 입력으로부터 다양한 특징을 추출해내고 그것에 따라서 최종 출력이 결정된다. <br />\n",
    "출력 단의 뉴런의 갯수는 분류하고자 하는 대상의 수에 따라 정해진다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 지도학습(supervised learning)을 사용하여, (입력값, 기대값)의 쌍으로 이루어진 학습 데이터를 이용해 학습을 한다. <br /> \n",
    "먼저 입력값을 인가하고 출력단에서 나오는 실제 출력값과 기대값의 차를 확인하면, 이것을 역전파(back-propagation) 방법을 사용하여 각각의 net 에 해당하는 <br /> \n",
    "파라미터(가중치, weight) 값을 조금씩 변화시키는 방식을 사용한다. <br /> \n",
    "이 과정을 반복적으로 수행을 하면 실제 출력값이 기대값에 수렴하게 되며, 일정 수준에 도달하게 되면 학습을 마친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Encoder는 모양만 놓고 보면, MLP와 비슷한 것 같지만 개념이 완전히 다르다. <br />\n",
    "아래의 그림은 가장 간단한 형태의 대표적인 AE의 구성을 보여주는 그림이다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/2.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AE는 입력과 출력의 차원이 같으며, 학습의 목표는 출력을 가능한 한 입력에 근사를 시키는 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AE 역시 MLP와 마찬가지로 hidden 레이어가 있는데, 보통은 hidden 레이어의 뉴런의 개수가 입력보다 작기 때문에 입력 레이어에서 hidden 레이어로 넘어가는 과정은 <br /> \n",
    "일종의 압축(encoding이라고도 함)이 필요하며, hidden 레이어에서 출력 레이어로 넘어갈 때는 반대(decoding이라고도 함)가 필요하다. <br />\n",
    "여기서 입력이 hidden 레이어로 넘어가면서 차원을 줄이는 과정은 실제로는 입력에서 의미 있는 특징을 뽑아내는 과정이라고 이해를 하면 좋을 것 같다. <br />\n",
    "그래서 AE를 이용한 학습에서는 hidden 레이어가 매우 중요 하며, 보통은 차원을 줄여주기 때문에 AE의 주요 응용 분야 중 하나가 \"dimensionality reduction\" 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Encoder가 MLP와 다른 점은 Auto Encoder는 자율 학습(un-supervised learning)이라는 점이다. <br /> \n",
    "자율 학습에서는 기대값이 필요 없으니, 단지 입력 데이터만을 넣어주면 학습을 통해 각각의 네트워크의 파라미터 값을 결정하게 된다. <br />\n",
    "출력 단은 자율학습에서 출력을 입력에 근사 시키기 위한 용도로 필요했기 때문에, 학습을 마치고 나면 의미가 있는 hidden 레이어만 남기고 출력단은 버린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약에 hidden 레이어에 있는 뉴런의 개수가 입력보다 크거나 같다면 어떤 일이 일어날까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 경우라면 identity 함수를 구현하는 것이 너무 쉽다. <br /> \n",
    "그냥 연결하고 남는 것들의 파라미터를 0으로 설정하면 되기 때문이다. <br /> \n",
    "결과적으로 어떤 중요한 정보도 추출할 수 없다는 것이다. <br />\n",
    "뭔가 유용한 feature를 얻어내려면 뉴런들이 identity 함수로 연결되는 것은 막는 제한 조건이 필요하며, 이것을 하려면 입력보다는 낮은 차원으로 연결해야 한다. <br />\n",
    "그러므로 AE는 입력보다 작은 차원을 갖는 hidden 레이어를 이용해 입력 데이터 속에 숨어 있는 변수(latent variable)들을 발굴할 수 있게 해준다. <br />\n",
    "차원 축소라면 흔히 사용되는 PCA(Principle Component Analysis)를 떠올릴 수도 있지만 PCA는 선형적인 한계가 있다. <br /> \n",
    "하지만 AE는 뉴런이 갖고 있는 non-linearity 성질 및 가해주는 constraints로 인해 훨씬 뛰어난 차원 축소 능력을 갖고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살핀 AE는 hidden 레이어가 1개만 있는 가장 간단한 구조였다. <br /> \n",
    "MLP에서 여러 개의 hidden 레이어를 이용해 좀 더 다양한 특징들을 끌어 냈듯이, AE도 hidden 레이어를 여러 개를 쌓아서 구현할 수 있는데 이것을 Stacked AE라고 부른다. <br />\n",
    "이해를 쉽게 하기 위해, 아래 그림처럼 hidden 레이어가 2개 있는 간단한 구조를 생각해 보자.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/3.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼핏 보기에는 복잡해 보이지만, hidden 레이어를 1개씩 떼어놓고 생각을 해보면 기본 AE가 적층되어 있는 것으로 볼 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 첫번째 Feature I의 경우를 보면 아래 그림과 같은 기본 AE로 이해할 수 있다. <br /> \n",
    "여기서 출력 단에는 가상의 출력 레이어가 있다고 생각을 하면 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/4.png\" width=300 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 Feature I을 입력으로 받아 Feature II를 hidden 레이어로 볼 수 있으며, 그 경우는 아래처럼 이해하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/5.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 많은 레이어가 있는 경우도 비슷하게 끊어서 생각하면, 결과적으로는 기본 AE 여러 개를 쌓아놓은 것과 같은 형태가 되며, 아래 그림과 같이 차원을 계속 줄여가는 구조가 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/6.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottleneck hidden layer에서는 가장 압축된 feature가 얻어지게 된다. <br /> \n",
    "Stacked AE를 학습시키는 방식은 \"Greedy Layer-Wise Training\"이라는 방법을 사용한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Layer-Wise Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2006년 이전에는 hidden 레이어가 2개 이상이 되는 딥 네트워크를 학습 시킬 방법이 별로 없어 고생을 하였다. <br /> \n",
    "몇 개의 CNN을 제외하면 거의 학습을 성공 시키지 못했다고 보는 편이 맞을 것 같다. <br /> \n",
    "그러다가 2006년이 되면서 약간의 시간차를 두고 신경망의 거장이라고 할 수 있는 Hinton, Bengio, LeCun 의 연구팀이 심층 네크워크를 학습시킬 수 있는 방법을 찾아낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그들이 발표한 논문은 각각 다음과 같다.\n",
    "\n",
    "- Hinton 팀(토론토 대학교): A Fast Learning Algorithm for Deep Belief Nets\n",
    "\n",
    "- Bengio 팀(몬트리올 대학교): Greedy Layer-Wise Training for Deep Networks\n",
    "\n",
    "- LeCun 팀(뉴욕 대학교): Efficient Learning of Sparse Representations with an Energy-based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이들의 연구로 드디어 심층 네트워크를 학습할 수 있는 방법이 열리게 된다. <br /> \n",
    "그 동안 심층 신경망 학습을 괴롭히던 문제는 Vanishing/Exploding gradient 문제와 Overfitting 문제였다. <br /> \n",
    "특히 뉴런의 활성함수로 sigmoid나 hyper-tangent 계열의 비선형 포화 함수(nonlinear saturation function)를 쓰는 경우에, 에러를 역전파(back-propagation) 시키면서 <br /> \n",
    "학습을 하다 보면, 입력의 절대값이 작은 일부 구간을 제외하면, 미분값이 0 근처로 가기 때문에 역전파를 이용한 학습이 어려워지거나 심각하게 느려지는 문제가 발생할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/7.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제를 피할 수 있는 방법 중 하나가 Greedy Layer-Wise Training 방법이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방법은 기본적인 AE(AutoEncoder)의 경우는 hidden 레이어가 1개이고, 자율 학습(unsupervised learning)의 방법으로, 입력 데이터 $x$를 학습한 후 <br /> \n",
    "출력이 다시 $x$에 근접한 값이 나오도록 파라미터 값을 결정한다는 것을 알았다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/8.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 학습 방법은 지도학습(supervised learning)의 경우처럼 오차를 역전파 시키는 방식을 사용한다. <br /> \n",
    "지도학습에서는 기대값과 실제 출력값을 차를 역전파 시키면서 학습을 수행하지만, AE에서는 출력단에서 입력 $x$와 실제 출력값을 차를 이용하며 역전파 방식은 거의 동일하다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 학습을 마치고 최종단을 제거하면 hidden layer인 h는 입력 데이터에 숨어 있는 특징을 추출할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked AE는 hidden 레이어가 여러 개 있는 구조로, 이것을 신경망 쪽의 전문 용어로 표현하면 capacity가 커졌기 때문에, hidden 레이어가 1개 있을 때보다 <br /> \n",
    "훨씬 다양한 함수를 표현할 수 있다.\n",
    "하지만 아무리 유용하더라도 학습이 불가능하면 무용지물이 되는데 이 때 사용할 수 있는 방법이 바로 Greedy layer-wise training 방법이다. <br /> \n",
    "이 방법의 기본 개념은 아래 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 시키는 방법은 말 그대로 레이어 별로 (탐욕스럽게) 학습을 시키는 것이다. <br /> \n",
    "이해를 돕기 위해 위 그림처럼, 3개의 hidden 레이어가 있는 Stacked AE를 학습시키는 경우를 생각해보자.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 위 그림의 (a)처럼 첫번째 hidden 레이어에 대한 학습을 진행한다. <br />\n",
    "이 때는 두 번째 및 세 번째 hidden 레이어는 없는 것으로 가정을 하고, 첫번째 hidden 레이어만 있다고 가정을 하고 학습을 시킨다. <br /> \n",
    "Hidden 레이어가 1개뿐이기 때문에 자율학습(unsupervised learning) 방법으로 학습이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 두 번째 hidden 레이어를 학습을 시킨다. <br /> \n",
    "두 번째 hidden 레이어를 학습시키는 경우는 학습을 시킨 첫 번째 hidden 레이어의 파라미터는 고정을 시킨다. <br /> \n",
    "그러면 두 번째 hidden 레이어의 입력은 첫 번째 hidden 레이어의 입력을 사용하는 것이나 마찬가지 상황이 되면 결과적으로 기본 Auto Encoder가 된다. <br />\n",
    "세 번째 hidden 레이어는 없다고 생각을 하고 학습을 시켜 두 번째 hidden 레이어의 파라미터를 결정한다. <br />\n",
    "세 번째 hidden 레이어의 학습은 첫 번째와 두 번째 hidden 레이어의 파라미터는 고정을 시킨다. <br /> \n",
    "그리고 두 번째 hidden 레이어의 출력을 입력으로 간주하면 역시 기본 Auto Encoder이기 때문에 학습이 가능해진다. <br />\n",
    "이런 방식으로 학습을 시키면, 여러 개의 hidden 레이어가 있는 경우에도 학습이 가능해지게 된다. <br /> \n",
    "이 방식이 2006년에 발표가 되면서 딥 러닝은 비로소 탄력을 받게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살펴본 방식은 Stacked AE에 대한 학습뿐만 아니라, 지도학습(supervised learning)을 사용하는 일반 신경망이나 CNN의 학습에도 이용을 할 수 있다. <br />\n",
    "신경망을 제대로 학습 시키려면 많은 학습 데이터가 필요한데, 라벨이 달리 학습 데이터는 부족하지만 라벨이 별로 없는 학습 데이터는 많은 경우가 있다. <br />\n",
    "이 경우 라벨이 없는 학습 데이터를 이용해 신경망의 각 레이어를 앞서 설명한 방식으로 사전 학습(pre-training)을 시킬 수가 있다. <br /> \n",
    "이것을 unsupervised pre-training이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 레이어에 대한 파라미터가 어느 정도 결정이 되면, 이후에 label이 달린 학습 데이터를 이용해 supervised fine-tuning을 시킬 수 있게 된다. <br />\n",
    "이렇게 학습을 시키는 방식은 2006년 이후로 몇 년간 심층 네트워크에 대한 학습 방법의 정석으로 인정이 되었었지만, 나중에 거의 쓰이지 않게 된다. <br />\n",
    "그 이유는 2010년이 넘어가면서 sigmoid나 hyper-tangent의 문제를 해결한 ReLU(Rectifier Linear Unit)이라는 활성화 함수가 발표되었으며, <br /> \n",
    "drop out, max out, data augmentation 및 결정적인 batch normalization 방법이 발표되면서, 굳이 피곤하게 unsupervised pre-training 방법을 사용하지 않아도, <br /> \n",
    "supervised 방식만으로 더 좋은 성능을 얻을 수 있게 되었기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 논문을 참고하면 좋을 것 같다.\n",
    "\n",
    "- Why Does Unsupervised Pre-training Help Deep Learning (2010)\n",
    "\n",
    "- An Analysis of Unsupervised Pre-training in Light Of Recent Advances (2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Unsupervised Pre-training](https://www.youtube.com/watch?v=Oq38pINmddk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising Auto Encoder는 2008년 몬트리올 대학교의 Pascal Vincent 및 Yoshua Bengio 등이 발표하였으며, <br />\n",
    "논문 제목은 “Extracting and Composing Robust Features with Denoising AutoEncoder”이다. <br />\n",
    "원래 AutoEncoder는 자율학습(unsupervised)을 이용하여 입력 데이터에 숨어 있는 중요한 특징(feature)을 파악하는 용도로 개발이 되었으며, <br /> \n",
    "지금과 같은 딥러닝 학습 기술들이 발표되기 전까지는 pre-training 용도로 많이 사용이 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데, 왜 AutoEncoder 앞에 Denoising이라는 말이 붙었을까? <br />\n",
    "Denoising의 사전적 의미는 “잡음을 제거하다”의 뜻이니, Denoising AutoEncoder는 “잡음을 제거할 수 있는 AE” 정도의 의미가 된다. <br />\n",
    "그렇다면, 어떻게 잡음 제거가 가능한 것일까? 이 질문에 대한 답을 하려면 다시 기본 AE를 살펴보면 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/10.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 AE는 위 그림처럼 Encoder와 Decoder로 구성이 되며, Encoder는 입력 데이터에 숨어 있는 중요한 특징을 압축된 형태로 추출을 해내고, 디코더는 그것을 다시 복원한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 중요한 특징을 추출하는 hidden 레이어의 뉴런의 개수는 입력보다 작기 때문에 데이터를 압축 시키는 효과를 거둘 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/11.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 생각할 수 있는 내용은 입력 데이터에 약간의 잡음이 있더라도, 핵심(본질)이 유지가 되면 출력은 어느 정도 원 이미지를 복원해낼 수 있다는 점이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 AE의 학습은 출력 $\\overset { \\sim  }{ X }$가 입력 $x$와 차이가 최소가 되도록 학습을 시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising AutoEncoder는 복원 능력을 더 강화하기 위해 기본적인 AE의 학습 방법을 조금 변형을 시킨 것이다. <br />\n",
    "Denoising AE의 개념은 아래 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 잡음이 없는 원 이미지 $x$에 잡음을 가하여 잡음이 있는 이미지 $\\overset { \\sim  }{ X }$를 만들어 낸다. <br /> \n",
    "이 때 잡음을 가하는 방법은 여러 가지 방식이 있을 수 있지만, 논문에서는 위 그림처럼 잡음의 위치에 있는 픽셀값을 모두 “0”으로 만들었다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 후 기본 AE에 원래 영상 $x$가 아니라 잡음이 있는 이미지 $\\overset { \\sim  }{ X }$를 입력하고, 출력 $z$가 잡음이 있는 이미지가 아니라 $x$와 가까워 지도록 학습을 시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것을 좀 더 쉽게 설명한 그림은 아래 그림과 같다. 원 이미지 $x$를 잡음을 추가하는 과정 $p(\\overset { \\sim  }{ X }|x)$를 거쳐 $\\overset { \\sim  }{ X }$를 얻어낸다. <br /> \n",
    "아래 그림처럼 잡음에 해당 하는 위치의 픽셀값이 0으로 바뀐다. <br /> \n",
    "이렇게 잡음이 추가된 이미지를 기본 AE의 입력으로 사용한다. <br /> \n",
    "출력 $z$가 $x$에 근접하도록, 즉 $x$와의 차가 최소화 되도록 학습을 시키면, 바로 그것이 Denoising AutoEncoder가 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/13.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에서는 이 과정을 manifold를 사용하여 다른 방식으로도 설명하였다. 아래 그림에서 실선 근처에 있는 $x$는 잡음이 없는 원래의 이미지를 의미하며, <br /> \n",
    "잡음을 가하게 되면 $\\overset { \\sim  }{ X }$를 manifold에서 멀어지게 하며, 학습을 통해서 다시 실선 근처로 가져가는 것을 Denoising AutoEncoder라고 하였다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder에 대한 실험 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에서는 실험을 위하여 hidden 레이어가 3개 있는 stacked denoising AutoEncoder를 사용하였으며, test에 사용할 데이터는 MNIST 데이터를 이용하였다. <br />\n",
    "테스트에 사용한 데이터는 basic은 기본 MNIST 데이터고, rot, bg-rand, bg-img 및 rot-bg-img는 아래 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/14.png\" width=500 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rect 및 rect-img는 아래와 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/15.png\" width=700 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convex 이미지는 아래와 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/16.png\" width=700 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 데이터들을 기반으로 하여 다른 방식들과 비교 실험을 하였다. <br /> \n",
    "실험 방식으로는 Gaussian kernel을 사용하는 SVMrbf, polynomial kernel을 사용하는 SVMpoly, hidden 레이어가 1개인 DBN-1, hidden layer가 3개인 DBN-3, <br /> \n",
    "SdA-3는 실험에 사용할 stacked denoising AutoEncoder이고 SAA-3는 SdA-3에서 잡음 비율이 0%인 특수한 경우이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험에 대한 결과는 아래 표와 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험 데이터와 크게 상관없이 분류 성능이 SdA-3에서 좋게 나오는 것을 확인할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면, Denoising AE를 통해서 얻어지는 필터 특성은 잡음 비율에 따라 어떤 양상을 보일까?\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/18.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잡음이 별로 없는 경우, 첫번째 hidden 레이어에서는 별다른 특징을 추출하는 것처럼 보이지 않는다. <br /> \n",
    "하지만, 잡음의 비율이 높아지게 되면, 필터는 local한 특징보다는 점차 global한 특징을 추출하게 된다. <br /> \n",
    "50% 에러가 추가된 그림을 보면, 필터는 잡음이 없었을 때와 달리 거의 글자에 가까워지는 것을 확인할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img src=\"./Images/19.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 결과를 보이는 이유는 잡음이 많아지면서, denoising autoencoder의 학습 과정이 결과적으로는 좀 더 분명한 특징을 학습하도록 만들어주는 것으로 해석된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Denoising AutoEncoder에 대한 설명이 잘된 동영상 자료](https://www.youtube.com/watch?v=t2NQ_c5BFOc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이타에 대한 표현: Complete or Overcomplete?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 신호는 푸리에나 웨이블렛의 경우처럼 기저함수(basis function)의 선형적인 결합으로 나타낼 수가 있다. <br /> \n",
    "대부분은 기저함수의 차원은 표현하고자 하는 데이터의 차원과 같으며, 이럴 때를 “complete 하다”라고 한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/20.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 수식은 데이터 $x$를 A라는 기저함수의 집합 (전문 용어로는 Dictionary 또는 Codebook이라고 부름)에 $s$라고 불리는 벡터를 곱해주는 형태가 되며, <br /> \n",
    "차원이 모두 n으로 동일하다. <br /> \n",
    "여기서 A가 정해지면, $s$는 $x$를 표현하는 벡터가 된다. <br /> \n",
    "Complete한 경우는 $s$와 $x$의 차원은 동일하며, $x$를 나타내는 $s$는 유일하다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한편 신호를 보다 밀도 있게(compact) 표현하는 방법은 크게 보면, 아래 그림과 같이 2개의 방식이 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/21.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 중 하나는 전에 살펴보았던 ‘기본 AutoEncoder’의 경우처럼, 입력보다 차원을 줄여서 입력 데이터 속에 숨어 중요한 정보를 encoding 하는 경우이다. <br /> \n",
    "즉 표현하고자 하는 데이터를 차원이 최소가 되도록 만드는 방식을 말한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방법으로 sparse coding이 있다. <br /> \n",
    "Sparse coding의 수식은 아래와 같으며, 사용하는 기저함수의 차원($m$)이 원 데이터의 차원($n$) 보다 크다. ($m>n$)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/22.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse coding에서 사용하는 기저함수 처럼, 표현하고자 하는 데이터보다 차원이 큰 경우를 “overcomplete 하다”라고 한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete한 기저함수를 사용하게 되면, 데이터를 표현할(representing data) 수 있는 방법이 고유하지만, overcomplete 한 경우에는 나타낼 수 있는 방법이 <br />\n",
    "하나가 아니라 여러 개가 가능하기 때문에 무언가 기준을 가지고 많은 것들 중에서 선택을 해줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원 데이터의 차원보다 크게 하면서 좀 더 밀도 있게 표현이 가능하다라는 말이 서로 모순된 것처럼 보이지만, 위 수식에 있는 벡터 $s$에서 대부분의 계수들을 0으로 한다면, 즉 활성화 되는 계수들의 숫자를 소수(작은 수)로 제한을 한다면, 기저함수의 차원은 커졌지만, 결과적으로 밀도 있게 표현할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Visual Cortex V1의 성질"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1962년 하버드의 Hubel과 Wiesel은 실험을 통하여 primary visual cortex V1의 성질을 밝힌다. <br /> \n",
    "Visual cortex 영역에는 simple cell, complex cell, hyper-complex cell로 구성이 된다. <br />\n",
    "Simple cell의 receptive field는 “spatially localized, oriented, bandpass”한 성질을 갖는다. <br /> \n",
    "Simple cell의 뉴런은 많은 세포로 구성이 되었지만 어떤 특정 순간에는 몇 개의 뉴런만 활성화가 되어 있어, 기본적으로 sparse coding과 비슷한 성질을 갖고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolutional Neural Network)의 기본 개념도 convolution을 적용하는 영역(이것을 receptive field)라고 부르는데, 기본적으로 local connectivity 개념에 <br /> \n",
    "기반을 하고 있기 때문에 일부 영역(local)만을 필터(convolution) 연산에 사용을 한다. <br /> \n",
    "FC 레이어의 경우는 모든 입력을 동일한 중요도를 갖는다고 보기 때문에 모두 연결을 하지만, convolutional layer에서는 1픽셀 당 1개의 connection만 <br /> \n",
    "가져가는 sparse connection의 형태를 취한다. <br />\n",
    "또한 특정 방향의 엣지들을 검출할 수 있도록 방향성을 갖고 있기 때문에 사람들이 엣지에 민감한 것도 여기에서 기인한다. <br />\n",
    "아래 그림은 고양이의 simple cell 영역에 전극을 꽂고 막대 형태의 조명을 비췄을 경우 특정 방향으로 자극이 크게 나타나는 것을 확인할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/23.png\" width=500 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse coding은 자율학습(unsupervised learning) 방법으로, overcomplete 기저벡터를 기반으로 데이터를 좀 더 효율적으로 표현하기 위한 용도로 개발이 되었다. <br />\n",
    "1996/97년 Olshausen과 Field가 발표한 논문 “Emergence of simple cell receptive field properties by learning sparse code for natural images”와 <br /> \n",
    "“Sparse coding with an overcomplete set: a strategy employed by V1”를 통해 primary visual cortex의 동작을 sparse code를 통해 <br />\n",
    "체계적으로 설명할 수 있음을 보여줬고, 그 이후 많은 논문들이 꾸준히 발표가 되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림은 sparse coding을 설명할 때 흔히 사용되는 그림이다. <br /> \n",
    "여기서 Dictionary D는 column 방향으로 흔히 atom이라고 부르는 기저벡터를 갖고 있으며, 데이터 $X$를 $\\alpha$로 나타낸다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/24.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $\\alpha$는 그림에서 볼 수 있는 것처럼, 빨간색에 해당하는 부분만, 0이 아니기 때문에 결과적으로는 해당 위치에 기저벡터를 $\\alpha$의 각 원소만큼 곱해서 더하는 방식으로 표현이 된다. <br />\n",
    "0이 아닌 원소의 개수가 3개이기 때문에 이전 입력보다는 좀 더 밀도 있게 표현이 가능해진 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 풀어줘야 할 부분은 D와 $\\alpha$를 어떻게 구할 수 있느냐 하는 것이다. <br />\n",
    "아래와 같은 행렬 형태로 바꾸어서 생각을 할 수가 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/25.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식에서 첫 번째 항목은 reconstruction error를 나타내는 부분으로 AD를 이용해 $X$를 얼마나 잘 표현할 수 있는지를 나타내고, 두 번째 항목은 일종의 <br /> \n",
    "penalty에 해당하며 기저 벡터 $\\alpha$에서 0이 아닌 element의 개수를 제한하는 방향으로 penalty 역할을 해준다. <br /> \n",
    "결과적으로 위 식을 최소화 하는 것이 목표이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식을 풀어내는 기본적인 방법은 Matching pursuit(MP)와 Basic pursuit(BP)라는 방식이 있고, 이후에도 많은 변형된 방식들이 나오며, 최근까지도 꾸준히 논문이 나오고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좀 더 이해를 쉽게 하기 위해 다음 그림을 검토해보자. <br /> \n",
    "자연 이미지의 특정 patch를 이용해 그림처럼 64개의 원소를 갖는 dictionary를 구한다. (unsupervised learning에 해당)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/26.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제에서는 주로 다양한 에지를 표현할 수 있는 벡터들이 구해진 경우이며, 이렇게 벡터를 구하고 실제 test를 하는 경우는 기저벡터 중 3개의 원소만 0이 아닌 값으로 <br /> \n",
    "test 샘플을 근사시킨다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 sparse coding을 이용하면, data compression이나 잡음 제거 및 컬러 interpolation 등에서 탁월한 효과를 얻을 수 있다. <br />\n",
    "아래 예는 denoising에 sparse coding을 효과적으로 적용한 예이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/27.png\" width=500 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 예는 inpainting(영상 복원 기술)에 sparse coding을 적용한 경우이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/29.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sparse coding 참고 자료1](http://www.cs.ubc.ca/~schmidtm/MLRG/sparseCoding.pdf) <br />\n",
    "[Sparse coding 참고 자료2](http://redwood.berkeley.edu/vs265/sparse-coding-slides.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sparse coding에 대한 설명이 잘된 동영상 자료](https://www.youtube.com/watch?v=7a0_iEruGoM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Coding과 AutoEncoder 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터를 대표할 수 있는 몇 개의 작은 활성화된 코드만을 이용하여, 원래의 신호를 복원해낼 수 있다는 것은 굉장히 매력적다. <br /> \n",
    "그래서 Sparse coding에 대한 연구가 활발하게 진행이 되었고, 최적의 solution을 구할 수 있는 많은 방법들이 발표가 되었다. <br />\n",
    "그런데 우리가 앞서 살펴본 기본 AutoEncoder 역시 통상적으로 encoding 단계에서 입력보다 더 작은 유닛으로 표현(representation)하는 과정을 거치기 때문에, <br /> \n",
    "어찌 보면 Sparse coding과 비슷하다. <br /> \n",
    "아래 그림에서 Compact coding에 해당하는 부분을 구현한 예를 AutoEncoder로 생각할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/30.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면, AutoEncoder와 Sparse Coding은 차이가 없는 것일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇지 않다. <br /> \n",
    "Sparse coding의 cost function은 기본적으로 아래와 같은 식으로 표현이 가능한데, 아래 식의 왼쪽은 reconstruction error를 부분을 나타내고 <br /> \n",
    "오른쪽은 sparsity를 강제하기 위한 일종의 penalty 항목이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/31.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, Auto Encoder의 cost function에는 sparsity를 강제하기 위한 항목이 없고, 기본적으로는 reconstruction error에 해당하는 부분만 있다. <br /> \n",
    "그러나 Auto Encoder의 경우도 hidden unit의 수를 입력보다 작게 함으로써 결과적으로는 compact coding의 효과를 얻을 수 있다는 점은 비슷하다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연 이미지 데이터에 대하여 Sparse coding이나 AutoEncoder는 비슷한 D(dictionary 또는 weight matrix)를 보여주지만, 일반적으로는 AutoEncoder가 <br /> \n",
    "일반화에 쉽고 더 복잡한 문제를 다룰 수 있다. <br /> \n",
    "또한 레이어 수를 여러 단으로 구성을 하여 더 복잡한 non-linearity를 표현할 수 있다는 점 및 cost function을 오차의 제곱이 아닌 다른 함수를 사용할 수 있다는 점도 <br /> \n",
    "AutoEncoder의 장점으로 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면, Sparse AutoEncoder는 어떤 장점이 있는 것일까? <br /> \n",
    "Sparse AutoEncoder는 Sparse coding과 AutoEncoder의 장점을 합친 것이라고 생각할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse AutoEncoder의 기본 구조는 아래 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/32.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림에서 hidden 레이어에는 총 500개의 unit이 존재하지만, 기본적인 Auto Encoder처럼 reconstruction error에 기반한 weight matrix $W$를 구하는 것이 아니라 <br /> \n",
    "여기에 sparsity 조건을 강제함으로써 hidden unit에 존재하는 뉴런의 활성화를 제한하는 Auto Encoder를 Sparse AutoEncoder라고 부른다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alireza Makhzani가 2013년말에 발표된 “k-Sparse AutoEncoder”는 매우 효율적으로 Sparse coding을 AutoEncoder로 쉽게 구현할 수 있는 방법을 제시하였다. <br /> \n",
    "([논문 링크](http://core.ac.uk/download/pdf/24989103.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Sparse AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse coding은 기본적으로 ‘dictionary learning’과 ‘sparse encoding’의 2 단계 과정으로 구성이 되며, 이것을 수행하기 위한 많은 알고리즘들이 발표가 되었다. <br />\n",
    "Sparse coding에서 ‘dictionary learning’ 과정은 학습 데이터를 이용하여 dictionary와 sparse code 벡터를 구하며, 이 과정에서 sparsity 조건을 <br /> \n",
    "같이 만족시켜줘야 하는데 통상적으로는 convex 함수가 아니기 때문에 gradient를 통해 접근을 하게 되면, local minimum에 빠지는 문제가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제를 해결하기 위해 greedy algorithm이나 relaxation 방법으로 대표되는 많은 방법이 발표되었지만, 연산시간이나 연산의 결과가 만족스럽지 못한 경우가 많았다. <br /> \n",
    "이후 iterative hard/soft thresholding 방법이 발표되면서 연산량도 많이 줄고 결과도 좋아지게 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 상황에서 k-Sparse AutoEncoder는 비교적 손쉽게 Sparse coding을 할 수 있는 방법을 제공하였다. <br /> \n",
    "Hidden 레이어에서의 activation을 최대 $k$개로 제한하는 방법을 적용하여 sparsity 조건을 적용하여, 크기가 $k$번째가 되는 뉴런까지는 그 결과를 그대로 사용하고, <br /> \n",
    "나머지는 모두 0으로 만들었다. <br /> \n",
    "Back-propagation 시에도 activation이 0인 path는 무시가 되고, 0이 아닌 쪽의 weight만 수정이 된다. <br />\n",
    "이 과정은 dictionary learning 과정으로 볼 수가 있으며, 새롭게 구성된 dictionary, 즉 weight matrix에 의해 다시 학습을 반복적으로 수행을 하게 되면, <br /> \n",
    "새로운 $k$개의 뉴런이 활성화 되고, 그것에 기반하여 다시 새로운 dictionary의 atom이 구해지게 된다. <br />\n",
    "결과적으로 보면 $k$개의 뉴런만을 활성화시켜 weight matrix를 학습하는 전형적인 과정이 Sparse coding의 dictionary 및 code vector를 학습하는 과정과 동일한 과정이 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/33.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 표에서 ${supp}_{k}({W}^{T}x+b)$가 바로 $k$개의 support vector를 구하는 과정이 되며, 3)번 과정은 그것을 바탕으로 weight matrix의 해당 atom을 update 하는 과정이 된다. <br />\n",
    "위 표를 보면, 학습(training) 과정에서는 $k$개의 활성화된 뉴런을 사용하지만, Sparse encoding 과정에서는 $k$개가 아니라 $\\alpha k$개인데 이것은 $k$만 <br /> \n",
    "사용하는 경우보다 1보다 약간 큰 $\\alpha$를 사용하여 $k$개보다 좀 더 많은 활성화된 뉴런을 갖도록 encoding 하는 것이 효율적이기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Sparse AutoEncoder의 효율성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse coding은 기본적으로 dictionary의 성능에 따라 결과가 달라지게 된다. <br /> \n",
    "K-Sparse AutoEncoder의 경우도 좋은 성능을 얻으려면, 얻어지는 weight matrix $W$를 잘 구해야 한다. <br />\n",
    "여기서 성능이 좋다는 것은, Sparse coding에서는 overcomplete 기저 벡터를 사용하기 때문에 dictionary를 구성하는 atom 들 간의 유사도가 낮아야 하며, <br /> \n",
    "유사도가 낮다는 이야기는 결과적으로 1개의 atom을 다른 1~2개의 atom들의 linear 합으로 표현하기가 어렵다는 의미가 되고, 결과적으로 수학적으로 특성이 우수는 <br />\n",
    "orthogonality에 근접하다는 이야기가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러므로 우수성 비교에는 atom들 간의 coherence를 체크하면 되는데, coherence는 결과적으로 벡터의 내적이 된다. <br /> \n",
    "내적이 작을수록 coherence가 작아지게 되고, 결과적으로 우수한 dictionary가 된다. <br />\n",
    "이것은 아래와 같은 수식으로 표현할 수 있게 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/40.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서로 같지 않은 atom들 간의 내적의 최대값이 바로 dictionary의 coherence가 된다. <br /> \n",
    "그러므로 k 값을 정할 때는 무턱대고 정하는 것이 아니라 $k\\le (1+{ u }^{ -1 })$의 조건을 만족시켜야 좋은 결과를 얻을 수 있게 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k 값에 따른 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Sparse AutoEncoder의 저자들은 $k$값의 변화에 따른 성능 실험을 수행하였으며, 일반적으로 $k$ 값이 큰 경우에는 local feature를 얻을 수 있기 때문에, <br /> \n",
    "classification에는 적합하지는 않지만 pre-training의 용도 등으로 활용하기에 유용하다. <br /> \n",
    "$k$ 값이 아주 작은 경우, 즉 너무 sparsity를 강조한 경우에는 너무 global한 특징을 얻게 돼 입력을 전반적으로 보는 경향이 생겨 비슷한 것들조차 다르게 분류를 해낸다. <br /> \n",
    "적절한 $k$값을 사용하면 classification에 알맞는 global feature를 추출할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림은 논문의 저자들이 1000개의 hidden unit을 갖는 구조에 MNIST 데이터를 사용하여 $k$값을 달리하면서 얻은 필터들을 visualization 시킨 것이다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/34.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림을 보면 $k$가 70인 경우는 너무 local한 feature가 얻어지는 것을 알 수 있고, 반대로 $k$가 10인 경우는 너무 global한 feature가 얻어졌으며, <br /> \n",
    "k가 40 정도가 되면 global한 feature들이 얻어진다는 것을 알 수가 있고, k가 25일 때 최고의 결과가 나온다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 table은 별도의 fine-tuning 과정 없이, unsupervised learning만을 적용했을 때의 성능을 비교한 것이다. <br /> \n",
    "적절한 $k$값을 갖는 k-Sparse AutoEncoder를 이용하는 경우에 다른 unsupervised learning 방법에 비하여 좋은 결과를 얻을 수 있다는 것을 확인할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/35.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 실험을 한 결과도 Sparse AutoEncoder의 결과가 상당히 좋다는 것도 확인할 수 있었다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살핀 경우는 작은 이미지에 대한 실험이기 때문에 모든 이미지 데이터에 대하여 fully connected 방식의 처리가 가능하다. <br /> \n",
    "하지만, 이미지의 크기가 커진다면 fully connected 방식을 이용하여 AutoEncoder를 그것도 deep stacked AutoEncoder를 구현한다는 것은 불가능하다. <br /> \n",
    "Weight matrix의 크기가 어마어마 해지게 된다. <br />\n",
    "그러므로 이런 경우는 AutoEncoder라고 할지라도 convolution을 적용하는 것이 바람직하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoEncoder는 2012년 AlexNet이 발표되기 전까지 몇 년동안 딥 러닝의 고질적인 문제를 해결해주는 방식으로 사랑을 받았다. <br />\n",
    "2012년 이후에는 Supervised learning 방식의 탁월한 성능으로 인해 빛이 바래진 느낌은 있지만 Unsupervised learning 방식이라는 점에서는 여전히 그 가치를 인정받고 있다. <br />\n",
    "Convolutional AutoEncoder는 2011년 스위스의 Jonathan Masci 일행이 처음 발표하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문 제목: [Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction](http://pdfs.semanticscholar.org/1c6d/990c80e60aa0b0059415444cdf94b3574f0f.pdf)\n",
    "\n",
    "이 블로그에서는 그들의 논문보다는 2016년에 발표된 재미있는 논문을 중심으로 Convolutional AutoEncoder를 살펴볼 예정이다. <br /> \n",
    "이 논문은 AutoEncoder를 이용하여 특정 그림이 어느 화가가 그린 그림인지를 분류하는 것을 목적으로 했기 때문에 망의 이름을 DeepPainter라고 하였다.\n",
    "\n",
    "논문 제목: [DeepPainter: Painter Classification Using Deep Convolutional Autoencoders](http://elidavid.com/pubs/deeppainter.pdf)\n",
    "\n",
    "통상적으로 화가들의 그림은 100점 이내로 적고, 또한 보통의 신경망에서 사용하는 것처럼 학습 데이터의 수를 늘리는 data augmentation 방법을 적용할 수가 없다. <br />\n",
    "이렇게 학습 데이터의 양이 작기 때문에 기존의 Supervised learning 방법으로는 쉽게 학습 데이터에만 특화되면서 overfitting이 발생할 수 있다. <br />\n",
    "그러므로 이런 경우는 Supervised learning을 사용하는 것보다 AutoEncoder와 같은 Unsupervised learning 방법을 사용하여 학습시키는 것이 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepPainter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통상적인 CNN 네트워크의 구성은 아래의 그림처럼, 몇 개의 Conv 레이어와 pooling 레이어 뒤에 classification을 위한 FC 레이어가 온다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/36.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Painter에서는 Unsupervised learning 방법을 이용하여 학습을 시킨다. <br />\n",
    "그러기 위해서는 위 구조의 뒷 부분에 오는 FC 레이어를 분리하고, 앞쪽에 있는 Conv 레이어와 pooling 레이어 부분만을 AutoEncoder 방식으로 학습을 시킨다. <br /> \n",
    "이후에 Supervised learning 형태로 FC 레이어 부분을 fine tuning을 시켜준다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞부분은 결국 Stacked Convolutional AutoEncoder의 형태이며, AutoEncoder를 학습시키려면 \"Encoder + Decoder\"의 형태가 되어야 하기 때문에 <br /> \n",
    "가상의 Decoder 부분의 네트워크를 구성해줘야 하며, 아래 그림과 같은 형태가 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/37.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자세히 보면, 요즘 유행하는 FCN(Fully Convolutional Network)과 비슷한 모양임을 알 수가 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Painter에서는 max-pooling 방식을 사용하는데, 이것이 decoder network를 구성할 때 문제가 된다. <br /> \n",
    "즉, max-pooling 방식을 사용하는 경우는 pooling window에서 가장 큰 값을 선택하게 되는데, size가 줄어들고 나면 위치 정보를 잃어버리기 때문에, <br /> \n",
    "decoder를 구성할 때, 즉 unpooling을 수행할 때 어느 위치에 값을 넣어줄지 알 수가 없게 된다. <br />\n",
    "그래서 DeepPainter에서는 pooling 위치를 따로 저장을 해서, unpooling 시에 정확한 위치를 알 수 있도록 했으며, 방식은 아래 그림과 같다. <br /> Max-location 정보를 활용할 수 있도록 하였다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/38.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후의 학습 과정은 앞서 살펴본 전형적인 AutoEncoder 학습 과정과 동일 하다. <br /> \n",
    "즉, Unsupervised learning 방식을 사용하기 때문에 별도의 label이 필요가 없으며, encoder-decoder 관계의 구조상 출력은 입력을 복원하는 방향으로 <br /> \n",
    "loss function이 최소화 되도록 학습을 시켜주면 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에서는 램브란트, 고흐, 르느와르 등 3명의 화가의 그림 30점씩(총 120점)을 학습 데이터로 사용하였다. <br />\n",
    "Unsupervised learning 시에는 feature 학습의 성능을 높이기 위해서 Denoising AutoEncoder를 학습 시킬 때처럼 그림의 20% 정도의 픽셀을 무작위로 없앤 후 학습을 시켰다. <br /> \n",
    "학습율(learning rate)는 초반에 0.01로 시작을 하여 epoch가 진행될 때마다 0.98을 곱해서 줄여줬다. <br />\n",
    "CAE(Convolutional AutoEncoder)에 대한 학습을 마치면, decoder 부분은 이제 필요가 없으니 없애고, 그 자리에 본래 있던 classification을 위한 FC 레이어를 다시 연결 시킨다. <br />\n",
    "이제는 classifier 부분을 학습을 시킨다. 앞부분은 이미 학습이 되었으니 결과적으로는 fine-tuning에 해당이 된다. <br /> \n",
    "학습 데이터가 120개밖에 안되기 때문에, 데이터를 늘리는 효과를 얻기 위해 90%를 학습용으로 사용하고 나머지 10%는 validation 용으로 사용하며, <br />\n",
    "데이터를 번갈아 가면서 10번을 수행한다. <br />\n",
    "결과는 아래 표와 같으며 CAE 방식이 다른 어떤 방식보다 성능이 좋다는 것을 확인할 수 있었다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/39.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAE가 갖고 있는 Unsupervised learning 방법은 학습 데이터의 양이 적은 경우에 꽤 효과적이다.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
