{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률 모델링을 비솟해 기계학습 모델들은 변수들 사이의 상관관계를 수치적으로 계산하는 것에서 시작한다. <br />\n",
    "Energy Based Model은 이런 변수들 사이의 상관관계를 에너지로 인코딩하며, 에너지가 낮을수록 연관성이 높음을 의미한다. <br />\n",
    "주어진 데이터(x)에 대해서 가능한 모든 출력변수(y)들의 배열들{(x, y)}의 에너지인 E(x,y)는 각 배열의 연관성을 의미하며 <br />\n",
    "모델이 제시하는 출력값은 에너지값이 가장 작은 배열의 출력변수(y)가 된다. 즉 모델은 가능한 모든 배열에 대한 에너지값을 알고 있어야 하며 <br />\n",
    "이 모든 배열에 대한 에너지값을 정해주는 수학적인 함수가 필요하다. 학습이란 주어진 학습데이터들에 대해서 좋은 에너지 함수가 되도록 에너지 함수의 <br />\n",
    "파라미터를 수정하는 과정을 의미한다. 이러한 에너지 함수를 정의하고 좋은 에너지 함수를 측정하기 위해 손실함수를 정의해서 <br />\n",
    "손실함수를 최소화 시키는 방향으로 기계학습이 진행된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy Based Model은 Energy Function을 통해서 확률 분포를 정의하는 특징이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/1.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/2.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = partition function (상태합)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식은 다시 Visible -x 와 Hidden -h에 맞게 아래와 같이 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/3.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 Hidden -h 란 모델의 표현력을 증가시키기 위해 관측되지 않은 변수들을 추가시킨 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 시스템 내부에 가지고 있는 에너지 중 실제로 변환 될 수 있는 자유로운 에너지를 뜻한다. <br />\n",
    "아래와 같이 정의된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/4.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 확률을 에너지로 표현한 식에 대입하여 아래와 같이 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/5.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy Based Model은 Gradient Desent를 수행함으로써 모델을 학습하고, Training data likelihood값에 대해 최적화를 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 log_likelihood와 negative_log_likelihood를 정의하고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/6.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent의 정도로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/7.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와 위에 Free Energy 식을 이용하면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/8.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boltmann Machine은 Stochastic Recurrent Neural Network로, 에너지 모델을 확률로 해석한 모델이다. <br />\n",
    "각각 하나의 Visible Layer와 Hidden Layer로 구성되며 이 네트워크 전체를 하나의 에너지 모델로 간주한다. <br />\n",
    "Visible Layer와 Hidden Layer가 학습과정에서 에너지 함수를 이용하여 학습하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Boltzmann Machine은 Hidden Unit을 추가한 EBM의 특별한 형태이다. 또 Markov Random Field의 일종이다.\n",
    "- Unit들간의 연결에 제약이 없이 모두 연결될 수 있는 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./RBM_Images/9.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 위 다이어그램과 같이 Fully connect이므로 Weight를 구하는 계산과정이 너무 복잡하고 그로인해 실제적인 문제를 해결하는데 유용하지 않다. <br />\n",
    "이러한 Boltzmann Machine의 단점을 보완하는 방법으로 연결에 제약을 둠으로써(같은 Layer간의 노드 연결을 없앰) <br />\n",
    "실제적인 문제 해결에 이용하기 위해 고안된 것이 Restricted Boltzmann Machine이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/10.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Bolztmann Machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "- 기존의 BM에서 유닛들간의 연결에 특별한 제한을 걸어 학습 시간을 크게 줄여 실질적인 사용이 가능하도록 변형한 신경망\n",
    "- Visible Layer 1개, Hidden Layer 1개로 구성된 완전 이분 그래프 모델로 Visible Layer과 Hidden Layer 유닛들 간의 연결이 없음 <br />\n",
    "(BM의 식에서 U와 V가 0벡터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/01.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional Link로 서로 연결된 노드(Unit)으로 구성되어 있으며 노드들은 On/Off 상태를, 링크들은 Weight를 가집니다. <br />\n",
    "같은 Layer의 노드들끼리 연결되는 링크는 없고, 링크에 주어진 Weight는 양방향으로 노드에 동일하게 적용됩니다. <br />\n",
    "BM과 마찬가지로 열역학 법칙(에너지가 높은 곳에서 낮은 곳으로 이동)처럼 확률이 낮은 상태에서 높은 상태로 학습됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 RBM의 Energt function이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/12.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBM도 EBM의 일종이기 때문에 Free Energy와 Distribution은 그대로 따라간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/02.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy fucntion을 확률로 풀이한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/13.png\" width=700 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RBM도 마찬가지로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/14.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Distribution\n",
    "RBM의 구조에 의해 Input이 주어지면 Hidden Unit들 간에는 Conditionally independent하며 그 역도 동일하게 성립<br />\n",
    "이 속성이 계산시간을 크게 줄여주는 이유가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/03.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM with Binary units\n",
    "Binary unit이라고 가정하면 P(h|x)식을 전개하고 Conditionally independent하다는 속성을 이용해 P(h_i=1|x)을 얻을 수 있다. <br />\n",
    "그 역도 마찬가지 이다.\n",
    "- 아래 두 식은 뒤에서 Sampling 할 때의 Update rule이 된다.\n",
    "- 각 Unit이 0과 1 사이의 실수값인 경우로 확장한 것이 Gaussain_Bernoulli RBM이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/04.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Log-likelihood gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 위해 Negative Log-likelihood gradient를 계산하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/05.png\" width=1000 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 항을 Postive phase, 두번째 항을 Negative phase라고 한다. <br /> \n",
    "뒤에 Negative phase는 계산이 어려움으로 RBM에서는 Sampling을 통해 값을 추정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Equation with Binary Units\n",
    "RBM의 에너지 함수로부터 각 파라미터에 대한 편미분을 계산하면 아래와 같다.\n",
    "- 에너지 함수가 선형이기 때문에 미분값이 매우 간단해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/06.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RBM의 최종적인 Update Equation을 다음과 같이 얻을 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/07.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gibbs Sampling in RBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 확률 변수의 조건부 확률 분포가 주어졌으므로 Gibbs Sampling을 통해서 모델 자체의 분포에 의한 표본을 수집할 수 있다.\n",
    "- 임의의 데이터에서 출발해서 표집을 하면 초기에는 처음 값에 의존하지만 충분한 시간이 지난 후에는 초기 상태에 관계없이 <br />\n",
    "모델 자체에 기반한 표본을 수집할 수 있다.\n",
    "- 에너지 관점에서 설명하면 Gibbs Sampling을 충분히 많이 하면 RBM이 에너지 평형 상태에 도달하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/08.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrasive Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "Negative Phase를 모든 가능한 입력 데이터에 대한 기대값으로 계산하지 않고 모델의 에너지 평형 상태에서의 샘플값 하나로만 근사한다.\n",
    "- 모델이 에너지 평형 상태에 있다면 그 떄의 샘플값은 평균에 가까울 가능성이 높기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibbs Sampling을 이용해 샘플을 얻는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/09.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update rule을 다음과 같이 다시 쓸 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/010.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD-k with Alternative Gibbs Sampling [Hinton 02]\n",
    "- Gibbs Sampling의 시작을 임의의 값이 아니라 trainging data로 한다.\n",
    "- Gibbs Sampling을 무한번 하지 않고 K번만 한다.\n",
    "- 실질적으로는 1번만 해도 충분히 좋은 샘플을 얻을 수 있다. <br />\n",
    "Training을 할수록 보델이 가지는 분포는 Training set의 분포를 따라간다. 즉, Training data가 이미 모델의 분포를 어느 정도 <br />\n",
    "표현하고 있다는 것이다. 따라서 Training data로부터 샘플링을 시작하면 이미 어느 정도 수렴된 지점부터 샘플링을 시작하는 것이라고 볼 수 있어서 <br />\n",
    "1번만에 좋은 샘플을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1번 샘플링해서 얻어진 Visible data를 Reconstrunction이라고 하고 트레이닝이 제대로 되고 있다면 Reconstruction error가 감소한다. <br />\n",
    "즉, 이상적인 RBM은 input data를 집어넣으면 동일한 Reconstruction Visible data를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/011.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibbs Sampling을 할 때 기존 CD-k 에서는 매 번 각각의 Training data에 대해 샘플링 하지만 Persistent CD에서는 이전 Gibbs Sampling에서 <br /> 계산된 data(Reconstruction data)를 다음 번 Sampling의 시작으로 사용한다. 즉 첫번째 Training data가 Persistent chain의 <br /> 시작이 되고 전번의 Gibbs Sampling 결과를 다음 번 Training의 시작으로 사용하여 Chain을 이어나간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 Chain을 이어 나가면 무한번 Sampling하는 것과 비슷해지는 효과를 갖게 된다. <br />\n",
    "물론 매 Gibbs Sampling마다 파라미터가 Update되어서 모델이 변하긴 하지만 매우 작은 값이기 때문에 근사적으로 성립한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./RBM_Images/012.png\" width=700 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
